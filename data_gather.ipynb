{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881c529-59bf-4953-b461-032a7cb8eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "BLOCK = 10 \n",
    "PAGE_LOAD = 100 #This could be 100, 50 or 10\n",
    "\n",
    "def extract_wallet_address(column):\n",
    "    pattern = r\"\\((0x[0-9a-fA-F]+)\\)\"\n",
    "    match = re.search(pattern, str(column))\n",
    "\n",
    "    if match:\n",
    "        wallet_address = match.group(1)\n",
    "    else:\n",
    "        pattern2 = r\"data-clipboard-text=\\\"0x[0-9a-fA-F]+\"\n",
    "        match = re.search(pattern2, str(column))\n",
    "\n",
    "        if match:\n",
    "            wallet_address = match.group().replace('data-clipboard-text=\\\"', '')\n",
    "        else:\n",
    "            wallet_address = None\n",
    "            \n",
    "    return wallet_address\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "#options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')  # no GUI#\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "block_counter = 0\n",
    "page_counter = 1\n",
    "prev = []\n",
    "\n",
    "hash_list = []\n",
    "block_list = []\n",
    "age_list = []\n",
    "from_list = []\n",
    "to_list = []\n",
    "value_list = []\n",
    "txn_fee_list = []\n",
    "    \n",
    "while(block_counter != BLOCK + 1):\n",
    "    url = 'https://etherscan.io/txs?ps=' + str(PAGE_LOAD) +'&p=' + str(page_counter)\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('tbody')\n",
    "    rows = table.find_all('tr')[1:]  \n",
    "   \n",
    "    for row in rows[:PAGE_LOAD]:\n",
    "        columns = row.find_all('td')    \n",
    "        current_block = columns[3].text.strip()\n",
    "        \n",
    "        if(current_block not in prev):\n",
    "            prev.append(current_block)\n",
    "            block_counter += 1\n",
    "        \n",
    "        if(block_counter > BLOCK + 1):\n",
    "            break;\n",
    "        \n",
    "        hash_list.append(columns[1].text.strip())\n",
    "        block_list.append(current_block)\n",
    "        age_list.append(columns[5].text.strip())\n",
    "        from_list.append(extract_wallet_address(columns[7]))\n",
    "        to_list.append(extract_wallet_address(columns[9]))\n",
    "        value_list.append(columns[10].text.strip())\n",
    "        txn_fee_list.append(columns[11].text.strip())\n",
    "        \n",
    "    page_counter += 1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Hash': hash_list,\n",
    "    'Block': block_list,\n",
    "    'Age': age_list,\n",
    "    'From': from_list,\n",
    "    'To': to_list,\n",
    "    'Value': value_list,\n",
    "    'Txn Fee': txn_fee_list\n",
    "})\n",
    "\n",
    "driver.quit()\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bb639-3abe-4bbf-bffb-00f9ce991a29",
   "metadata": {},
   "source": [
    "<b>Data Gathering Report</b>\n",
    "\n",
    "By using BeautifulSoup and selenium libraries we gather transactions of 10 blocks.\n",
    "There are 2 const variables called BLOCK and PAGE_LOAD that represent the number of blocks the user wants and how many transactions the user wants to gather in each scrabing.\n",
    "\n",
    "There is 2 options for webdriver either FireFox or Google Chrome that is commented(In my device using Google Chrome gets privacy error but FireFox opens in a perfect way it might be different in your IP connection)\n",
    "\n",
    "Let's get into algorithm the form of url link is https://etherscan.io/txs?ps=100&p=5 which the ps represents how many transactions are load in each url and the p represents the page number so till we gather 10 blocks transactions we're gathering all the transactions of page and then going to the next page.\n",
    "Extracting the data of each transaction and putting them to their corresponding list. After finishing the gathering we puth all the dat to a panda dataframe and save it into output.csv\n",
    "\n",
    "ChatGPT\n",
    "Data Gathering Report\n",
    "\n",
    "By utilizing the BeautifulSoup and Selenium libraries, we collected transactions from 10 blocks. There are two constant variables, BLOCK and PAGE_LOAD, which determine the number of blocks the user wishes to gather and how many transactions the user wants to scrape in each iteration.\n",
    "\n",
    "There are two options for the webdriver: either Firefox or Google Chrome, which are commented out. (Note: On my device, using Google Chrome results in a privacy error, but Firefox opens perfectly. This may vary depending on your IP connection.)\n",
    "\n",
    "Let's delve into the algorithm: the URL format is https://etherscan.io/txs?ps=100&p=5, where 'ps' represents the number of transactions loaded in each URL, and 'p' represents the page number. Therefore, to gather transactions from 10 blocks, we iterate through each page, extracting the data of each transaction and appending it to its corresponding list. Once gathering is complete, we compile all the data into a pandas dataframe and save it to output.csv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
