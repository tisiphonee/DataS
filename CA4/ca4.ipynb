{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading diabetes dataset and Examining the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes(scaled=False)\n",
    "\n",
    "df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   bmi     bp     s1     s2    s3   s4      s5    s6\n",
      "0  59.0  2.0  32.1  101.0  157.0   93.2  38.0  4.0  4.8598  87.0\n",
      "1  48.0  1.0  21.6   87.0  183.0  103.2  70.0  3.0  3.8918  69.0\n",
      "2  72.0  2.0  30.5   93.0  156.0   93.6  41.0  4.0  4.6728  85.0\n",
      "3  24.0  1.0  25.3   84.0  198.0  131.4  40.0  5.0  4.8903  89.0\n",
      "4  50.0  1.0  23.0  101.0  192.0  125.4  52.0  4.0  4.2905  80.0\n",
      "age    float64\n",
      "sex    float64\n",
      "bmi    float64\n",
      "bp     float64\n",
      "s1     float64\n",
      "s2     float64\n",
      "s3     float64\n",
      "s4     float64\n",
      "s5     float64\n",
      "s6     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.518100</td>\n",
       "      <td>1.468326</td>\n",
       "      <td>26.375792</td>\n",
       "      <td>94.647014</td>\n",
       "      <td>189.140271</td>\n",
       "      <td>115.439140</td>\n",
       "      <td>49.788462</td>\n",
       "      <td>4.070249</td>\n",
       "      <td>4.641411</td>\n",
       "      <td>91.260181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.109028</td>\n",
       "      <td>0.499561</td>\n",
       "      <td>4.418122</td>\n",
       "      <td>13.831283</td>\n",
       "      <td>34.608052</td>\n",
       "      <td>30.413081</td>\n",
       "      <td>12.934202</td>\n",
       "      <td>1.290450</td>\n",
       "      <td>0.522391</td>\n",
       "      <td>11.496335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.258100</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>96.050000</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.276700</td>\n",
       "      <td>83.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.620050</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.275000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>209.750000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.997200</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>242.400000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>6.107000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex         bmi          bp          s1          s2  \\\n",
       "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
       "mean    48.518100    1.468326   26.375792   94.647014  189.140271  115.439140   \n",
       "std     13.109028    0.499561    4.418122   13.831283   34.608052   30.413081   \n",
       "min     19.000000    1.000000   18.000000   62.000000   97.000000   41.600000   \n",
       "25%     38.250000    1.000000   23.200000   84.000000  164.250000   96.050000   \n",
       "50%     50.000000    1.000000   25.700000   93.000000  186.000000  113.000000   \n",
       "75%     59.000000    2.000000   29.275000  105.000000  209.750000  134.500000   \n",
       "max     79.000000    2.000000   42.200000  133.000000  301.000000  242.400000   \n",
       "\n",
       "               s3          s4          s5          s6  \n",
       "count  442.000000  442.000000  442.000000  442.000000  \n",
       "mean    49.788462    4.070249    4.641411   91.260181  \n",
       "std     12.934202    1.290450    0.522391   11.496335  \n",
       "min     22.000000    2.000000    3.258100   58.000000  \n",
       "25%     40.250000    3.000000    4.276700   83.250000  \n",
       "50%     48.000000    4.000000    4.620050   91.000000  \n",
       "75%     57.750000    5.000000    4.997200   98.000000  \n",
       "max     99.000000    9.090000    6.107000  124.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types are float64, so we ensured they are numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking missing data and Scaling data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the diabetes dataset, we opted for StandardScaler due to its effectiveness in handling features with varying magnitudes. This choice was motivated by the recognition that the dataset's features, such as blood pressure readings and body mass index (BMI) measurements, might exhibit different scales. StandardScaler was preferred for its robustness and suitability to our dataset's characteristics. While it maintains the shape of the original distribution of features, albeit centered at zero and scaled to unit variance, it also ensures that the scaled features still retain their original relative distances and relationships.\n",
    "\n",
    "StandardScaler standardizes features by removing the mean and scaling to unit variance, making it suitable for datasets where features have varying magnitudes. This approach ensures model stability by being less sensitive to outliers and preserves interpretability by retaining original feature distributions.\n",
    "\n",
    "In contrast, we refrained from using MinMaxScaler. This scaler scales features to a fixed range (for example [0,1]), which may be unsuitable for datasets with unknown feature distributions or varying magnitudes. Additionally, MinMaxScaler is more sensitive to outliers, which could distort the scaling process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data found!\n",
      "\n",
      "Number of instances in training set: 419\n",
      "Number of instances in testing set: 23\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "if missing_values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "else:\n",
    "    print(\"No missing data found!\\n\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, diabetes.target, test_size=0.05)\n",
    "\n",
    "print(\"Number of instances in training set:\", len(X_train))\n",
    "print(\"Number of instances in testing set:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dataset after scaling it to standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.800500  1.065488  1.297088  0.459841 -0.929746 -0.732065 -0.912451   \n",
      "1 -0.039567 -0.938537 -1.082180 -0.553505 -0.177624 -0.402886  1.564414   \n",
      "2  1.793307  1.065488  0.934533 -0.119214 -0.958674 -0.718897 -0.680245   \n",
      "3 -1.872441 -0.938537 -0.243771 -0.770650  0.256292  0.525397 -0.757647   \n",
      "4  0.113172 -0.938537 -0.764944  0.459841  0.082726  0.327890  0.171178   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.054499  0.418531 -0.370989  \n",
      "1 -0.830301 -1.436589 -1.938479  \n",
      "2 -0.054499  0.060156 -0.545154  \n",
      "3  0.721302  0.476983 -0.196823  \n",
      "4 -0.054499 -0.672502 -0.980568  \n"
     ]
    }
   ],
   "source": [
    "sdf = pd.DataFrame(data=scaled_features, columns=diabetes.feature_names)\n",
    "print(sdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Functions’ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the LaTeX formats for the formulas of the mentioned loss functions:\n",
    "\n",
    "1. **Mean Squared Error (MSE)**:\n",
    "$  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $\n",
    "\n",
    "2. **Mean Absolute Error (MAE)**:\n",
    "$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**:\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $\n",
    "\n",
    "4. **R² Score (Coefficient of Determination)**:\n",
    "$ R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "\n",
    "Where:\n",
    "-  **n** is the number of observations,\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ \\bar{y} $ is the mean of the actual values of the dependent variable.\n",
    "- $ SS_{\\text{res}} $ is the sum of squares of residuals,\n",
    "- $ SS_{\\text{tot}} $ is the total sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred, act):\n",
    "    mse = 0\n",
    "    n = len(pred)\n",
    "    for i in range(n):\n",
    "        value = (pred[i] - act[i]) ** 2\n",
    "        mse += value\n",
    "    mse /= n\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, act):\n",
    "    mae = 0\n",
    "    n = len(pred)\n",
    "    for i in range(n):\n",
    "        value = abs(pred[i] - act[i])\n",
    "        mae += value\n",
    "    mae /= n\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RMSE(pred, act):\n",
    "    mse = MSE(pred, act)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_Score(pred, act):\n",
    "    n = len(pred)\n",
    "    pred_sum = np.sum(pred)\n",
    "    pred_squared_sum = np.sum(np.square(pred))\n",
    "    act_sum = np.sum(act)\n",
    "    act_squared_sum = np.sum(np.square(act))\n",
    "    pred_act_sum = np.sum([pred[i] * act[i] for i in range(len(pred))])\n",
    "    numerator = n * pred_act_sum - pred_sum * act_sum\n",
    "    pred_term = n * pred_squared_sum - pred_sum ** 2\n",
    "    act_term = n * act_squared_sum - act_sum ** 2\n",
    "    denominator = math.sqrt(pred_term) * math.sqrt(act_term)\n",
    "    r2_score = numerator / denominator\n",
    "    return r2_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Building and Training the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_max = max(max(y_test), max(y_pred)) + 20\n",
    "plt_min = 0\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlim(plt_min, plt_max)\n",
    "plt.ylim(plt_min, plt_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|    Data Type/Optimizer       |          MSE          |          MAE          |          RMSE          |          R2 Score          |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|         Train Set               2894.75219305171140      43.65309822939592        53.80290134418135          0.71406480308851      |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|          Test Set               2302.75038820353984      35.89324763052433        47.98698144500798          0.80957325713099      |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "\n",
    "mse_train = MSE(y_train, y_train_pred)\n",
    "mae_train = MAE(y_train, y_train_pred)\n",
    "rmse_train = RMSE(y_train, y_train_pred)\n",
    "r2_train = R2_Score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "mae_test = MAE(y_test, y_pred)\n",
    "rmse_test = RMSE(y_test, y_pred)\n",
    "r2_test = R2_Score(y_test, y_pred)\n",
    "\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(\"|    Data Type/Optimizer       |          MSE          |          MAE          |          RMSE          |          R2 Score          |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(f\"|         Train Set               {mse_train:.14f}      {mae_train:.14f}        {rmse_train:.14f}          {r2_train:.14f}      |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(f\"|          Test Set               {mse_test:.14f}      {mae_test:.14f}        {rmse_test:.14f}          {r2_test:.14f}      |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set OLS Statistics:\n",
      "  Feature      Slope   Intercept  R2-value       P-value  Std Error\n",
      "0     age  13.664168  151.163014  0.031929  2.366227e-04   3.684491\n",
      "1     sex   3.648286  151.234005  0.002256  3.321248e-01   3.757353\n",
      "2     bmi  44.488674  151.696951  0.325119  1.687973e-37   3.138875\n",
      "3      bp  32.658086  151.692433  0.178549  1.416948e-19   3.430320\n",
      "4      s1  17.642635  151.289002  0.053520  1.697660e-06   3.633224\n",
      "5      s2  14.555841  151.275551  0.036390  8.519724e-05   3.667977\n",
      "6      s3 -30.377027  151.046821  0.154254  6.629579e-17   3.483201\n",
      "7      s4  33.106325  151.124193  0.191080  5.558892e-21   3.335704\n",
      "8      s5  43.775997  151.082161  0.324558  2.008978e-37   3.092546\n",
      "9      s6  28.667211  151.670158  0.140971  1.784678e-15   3.465422\n",
      "\n",
      "Test Set OLS Statistics:\n",
      "  Feature      Slope   Intercept  R2-value   P-value  Std Error\n",
      "0     age  36.213122  172.876416  0.171664  0.049347  17.358803\n",
      "1     sex  -0.237617  167.919845  0.000009  0.989245  17.418903\n",
      "2     bmi  52.050355  158.748238  0.671147  0.000002   7.950715\n",
      "3      bp  53.364114  155.230346  0.534813  0.000074  10.860569\n",
      "4      s1 -18.243808  168.410245  0.039088  0.365858  19.739135\n",
      "5      s2 -15.812973  168.166991  0.030221  0.427607  19.547218\n",
      "6      s3 -33.009782  172.273998  0.216803  0.025149  13.691037\n",
      "7      s4  38.166317  170.911966  0.108170  0.125438  23.914350\n",
      "8      s5  41.445633  171.108616  0.278487  0.009654  14.557572\n",
      "9      s6  47.230648  155.793582  0.252672  0.014502  17.725196\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "ols_stats_train = []\n",
    "for i in range(len(X_train.T)): \n",
    "    slope, intercept, r_value, p_value, std_err = linregress(X_train.T[i], y_train)\n",
    "    ols_stats_train.append({\n",
    "        'Feature': sdf.columns[i],\n",
    "        'Slope': slope,\n",
    "        'Intercept': intercept,\n",
    "        'R2-value': r_value ** 2,\n",
    "        'P-value': p_value,\n",
    "        'Std Error': std_err\n",
    "    })\n",
    "\n",
    "ols_stats_train_df = pd.DataFrame(ols_stats_train)\n",
    "ols_stats_test = []\n",
    "for i in range(len(X_test.T)): \n",
    "    slope, intercept, r_value, p_value, std_err = linregress(X_test.T[i], y_test)\n",
    "    ols_stats_test.append({\n",
    "        'Feature': sdf.columns[i],\n",
    "        'Slope': slope,\n",
    "        'Intercept': intercept,\n",
    "        'R2-value': r_value ** 2,\n",
    "        'P-value': p_value,\n",
    "        'Std Error': std_err\n",
    "    })\n",
    "\n",
    "ols_stats_test_df = pd.DataFrame(ols_stats_test)\n",
    "\n",
    "print(\"Training Set OLS Statistics:\")\n",
    "print(ols_stats_train_df)\n",
    "\n",
    "print(\"\\nTest Set OLS Statistics:\")\n",
    "print(ols_stats_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.510\n",
      "Model:                            OLS   Adj. R-squared:                  0.498\n",
      "Method:                 Least Squares   F-statistic:                     42.45\n",
      "Date:                Tue, 23 Apr 2024   Prob (F-statistic):           3.45e-57\n",
      "Time:                        16:09:53   Log-Likelihood:                -2264.4\n",
      "No. Observations:                 419   AIC:                             4551.\n",
      "Df Residuals:                     408   BIC:                             4595.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        151.6335      2.665     56.901      0.000     146.395     156.872\n",
      "x1            -0.2789      2.921     -0.095      0.924      -6.021       5.463\n",
      "x2           -11.6754      3.031     -3.852      0.000     -17.634      -5.717\n",
      "x3            24.7776      3.289      7.534      0.000      18.312      31.243\n",
      "x4            15.3906      3.223      4.775      0.000       9.054      21.727\n",
      "x5           -39.8672     20.299     -1.964      0.050     -79.770       0.036\n",
      "x6            23.6821     16.468      1.438      0.151      -8.690      56.054\n",
      "x7             6.0239     10.459      0.576      0.565     -14.537      26.585\n",
      "x8             9.5943      7.882      1.217      0.224      -5.901      25.089\n",
      "x9            38.1359      8.478      4.498      0.000      21.471      54.801\n",
      "x10            1.3724      3.245      0.423      0.673      -5.007       7.752\n",
      "==============================================================================\n",
      "Omnibus:                        1.686   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.430   Jarque-Bera (JB):                1.568\n",
      "Skew:                           0.050   Prob(JB):                        0.457\n",
      "Kurtosis:                       2.718   Cond. No.                         21.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "X = add_constant(X_train)\n",
    "model = OLS(y_train, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.722\n",
      "Method:                 Least Squares   F-statistic:                     6.725\n",
      "Date:                Tue, 23 Apr 2024   Prob (F-statistic):            0.00146\n",
      "Time:                        16:09:53   Log-Likelihood:                -111.15\n",
      "No. Observations:                  23   AIC:                             244.3\n",
      "Df Residuals:                      12   BIC:                             256.8\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        147.2583     10.408     14.148      0.000     124.581     169.936\n",
      "x1            -2.7606     13.791     -0.200      0.845     -32.809      27.287\n",
      "x2           -20.7704     11.223     -1.851      0.089     -45.223       3.683\n",
      "x3            41.2840     14.521      2.843      0.015       9.645      72.923\n",
      "x4            -6.3544     15.977     -0.398      0.698     -41.166      28.457\n",
      "x5          -125.0875    147.837     -0.846      0.414    -447.198     197.023\n",
      "x6            95.5882    121.072      0.790      0.445    -168.205     359.382\n",
      "x7            20.1417     63.827      0.316      0.758    -118.925     159.208\n",
      "x8           -32.9264     48.950     -0.673      0.514    -139.580      73.727\n",
      "x9            44.1844     45.236      0.977      0.348     -54.377     142.746\n",
      "x10           44.0502     15.791      2.790      0.016       9.644      78.457\n",
      "==============================================================================\n",
      "Omnibus:                        9.805   Durbin-Watson:                   2.847\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                7.796\n",
      "Skew:                          -1.109   Prob(JB):                       0.0203\n",
      "Kurtosis:                       4.794   Cond. No.                         45.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = add_constant(X_test)\n",
    "model = OLS(y_test, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "x1 = age\n",
    "\n",
    "x2 = sex\n",
    "\n",
    "x3 = bmi (body mass index)\n",
    "\n",
    "x4 = bp (blood pressure)\n",
    "\n",
    "x5 = s1\n",
    "\n",
    "x6 = s2\n",
    "\n",
    "x7 = s3\n",
    "\n",
    "x8 = s4\n",
    "\n",
    "x9 = s5\n",
    "\n",
    "x10 = s6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    " * The MSE for the training set (2837.47) is lower than the MSE for the test set (3330.65), which is expected because the model is typically optimized for the training data.\n",
    " * The MAE for the training set (43.05) is lower than the MAE for the test set (47.86), which is consistent with the MSE trend.\n",
    " * The RMSE for the training set (53.27) is lower than the RMSE for the test set (57.71), which aligns with the MSE and MAE results.\n",
    " * The R² score for the training set (0.71) is lower than the R² score for the test set (0.81), which is unexpected, as the model is typically expected to perform better on the training data. The higher R² score for the test set compared to the training set may indicate potential issues, such as overfitting or data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. \n",
    "\n",
    "**R² (R-squared)**:\n",
    "- The R² value, also known as the coefficient of determination, represents the proportion of the variance in the dependent variable (target) that can be explained by the independent variables (features) in the regression model.\n",
    "- It ranges from 0 to 1, where a value of 1 indicates a perfect fit, meaning the model explains 100% of the variance in the target variable.\n",
    "- A high R² value (closer to 1) suggests that the model fits the data well and can accurately predict the target variable based on the independent variables.\n",
    "- A low R² value (closer to 0) indicates that the model does not adequately capture the relationship between the independent variables and the target variable, and has a poor fit.\n",
    "\n",
    "**Adjusted R²**:\n",
    "- The Adjusted R² is a modified version of the R² that takes into account the number of independent variables and the sample size.\n",
    "- It adjusts the R² value downward to account for the potential overfitting that can occur when adding more independent variables to the model.\n",
    "- The Adjusted R² is always lower than or equal to the R² value, and it provides a more conservative estimate of the model's explanatory power.\n",
    "- A higher Adjusted R² value (closer to the R² value) suggests that the addition of independent variables is justified and improves the model's predictive power.\n",
    "- A lower Adjusted R² value (much lower than the R² value) may indicate that the additional independent variables are not contributing significantly to the model's performance, and the model may be overfitted.\n",
    "\n",
    "**Implications of High or Low Values**:\n",
    "- High R² and Adjusted R² values (close to 1) generally indicate a good fit and a strong relationship between the independent variables and the target variable. However, it's important to note that a high R² alone does not necessarily imply a useful or reliable model, as other factors like multicollinearity, outliers, and model assumptions should also be considered.\n",
    "- Low R² and Adjusted R² values (closer to 0) suggest that the model has a poor fit and may not be capturing the underlying relationship between the independent variables and the target variable effectively. This could be due to missing important features, incorrect model assumptions, or the presence of non-linear relationships that cannot be adequately captured by a linear regression model.\n",
    "\n",
    "**Differences between R² and Adjusted R²**:\n",
    "- The main difference between R² and Adjusted R² is that the Adjusted R² accounts for the number of independent variables and the sample size, while the R² does not.\n",
    "- The Adjusted R² is always lower than or equal to the R² value, and the difference between them becomes more significant as the number of independent variables increases relative to the sample size.\n",
    "- The Adjusted R² is useful for comparing models with different numbers of independent variables, as it penalizes models with an excessive number of predictors that do not significantly improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \n",
    "Explanation of p-values:\n",
    "\n",
    "The p-value is the probability of obtaining a test statistic at least as extreme as the one observed, assuming that the null hypothesis (the coefficient is zero) is true.\n",
    "In other words, the p-value represents the likelihood of observing the given result by chance if the independent variable has no effect on the dependent variable.\n",
    "A smaller p-value indicates stronger evidence against the null hypothesis, suggesting that the independent variable is statistically significant in predicting the dependent variable.\n",
    "\n",
    "Appropriate value for p-values:\n",
    "\n",
    "The conventional threshold for statistical significance is typically set at 0.05 (5%).\n",
    "If the p-value for an independent variable is less than 0.05, it is considered statistically significant, and we can reject the null hypothesis, indicating that the variable is likely to have a non-zero effect on the dependent variable.\n",
    "If the p-value is greater than 0.05, it is generally considered statistically insignificant, and we fail to reject the null hypothesis, suggesting that the variable may not have a significant effect on the dependent variable.\n",
    "\n",
    "Columns with suitable p-values:\n",
    "\n",
    "Based on the OLS regression results, the following columns (independent variables) have p-values less than 0.05, indicating statistical significance:\n",
    "\n",
    "x2: p-value = 0.000\n",
    "\n",
    "x3: p-value = 0.000\n",
    "\n",
    "x4: p-value = 0.000\n",
    "\n",
    "x5: p-value = 0.041\n",
    "\n",
    "x9: p-value = 0.000\n",
    "\n",
    "These columns are considered statistically significant predictors of the dependent variable (y) at the 5% significance level.\n",
    "The remaining columns (x1, x6, x7, x8, and x10) have p-values greater than 0.05, suggesting that they may not be statistically significant predictors of the dependent variable in this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. \n",
    "p-values:\n",
    "\n",
    "Features with p-values less than the conventional threshold of 0.05 are considered statistically significant.\n",
    "Based on the p-values, the most significant features in predicting the diabetic condition are:\n",
    "x2: p-value = 0.000\n",
    "x3: p-value = 0.000\n",
    "x4: p-value = 0.000\n",
    "x5: p-value = 0.041\n",
    "x9: p-value = 0.000\n",
    "\n",
    "Regression Coefficients:\n",
    "\n",
    "The regression coefficients represent the change in the dependent variable (diabetic condition) associated with a one-unit increase in the corresponding feature, holding all other features constant.\n",
    "Features with larger regression coefficients (in absolute value) have a greater impact on the dependent variable.\n",
    "Positive coefficients indicate a positive relationship (an increase in the feature leads to an increase in the diabetic condition), while negative coefficients indicate a negative relationship (an increase in the feature leads to a decrease in the diabetic condition).\n",
    "Based on the regression coefficients, the features with the largest impact (in absolute value) are:\n",
    "x3: Coefficient = 23.8486 (positive relationship)\n",
    "x4: Coefficient = 15.8448 (positive relationship)\n",
    "x5: Coefficient = -41.5275 (negative relationship)\n",
    "x9: Coefficient = 36.4579 (positive relationship)\n",
    "\n",
    "Feature Importance Assessment:\n",
    "\n",
    "Combining the information from p-values and regression coefficients, the most important features in predicting an individual's diabetic condition appear to be:\n",
    "\n",
    "x3: Statistically significant (p-value = 0.000) and positive relationship with a large coefficient (23.8486)\n",
    "x4: Statistically significant (p-value = 0.000) and positive relationship with a moderate coefficient (15.8448)\n",
    "x5: Statistically significant (p-value = 0.041) and negative relationship with a large coefficient (-41.5275)\n",
    "x9: Statistically significant (p-value = 0.000) and positive relationship with a large coefficient (36.4579)\n",
    "Features x2 and x6 also have relatively low p-values (0.000 and 0.109, respectively), indicating potential significance, but their coefficients are smaller in magnitude compared to the features mentioned above.\n",
    "\n",
    "Features x1, x7, x8, and x10 have relatively high p-values (> 0.05), suggesting they may not be statistically significant predictors of the diabetic condition in this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
