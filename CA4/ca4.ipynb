{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###.Loading.diabetes.dataset and Examining the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes(scaled=False)\n",
    "\n",
    "df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   bmi     bp     s1     s2    s3   s4      s5    s6\n",
      "0  59.0  2.0  32.1  101.0  157.0   93.2  38.0  4.0  4.8598  87.0\n",
      "1  48.0  1.0  21.6   87.0  183.0  103.2  70.0  3.0  3.8918  69.0\n",
      "2  72.0  2.0  30.5   93.0  156.0   93.6  41.0  4.0  4.6728  85.0\n",
      "3  24.0  1.0  25.3   84.0  198.0  131.4  40.0  5.0  4.8903  89.0\n",
      "4  50.0  1.0  23.0  101.0  192.0  125.4  52.0  4.0  4.2905  80.0\n",
      "age    float64\n",
      "sex    float64\n",
      "bmi    float64\n",
      "bp     float64\n",
      "s1     float64\n",
      "s2     float64\n",
      "s3     float64\n",
      "s4     float64\n",
      "s5     float64\n",
      "s6     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.518100</td>\n",
       "      <td>1.468326</td>\n",
       "      <td>26.375792</td>\n",
       "      <td>94.647014</td>\n",
       "      <td>189.140271</td>\n",
       "      <td>115.439140</td>\n",
       "      <td>49.788462</td>\n",
       "      <td>4.070249</td>\n",
       "      <td>4.641411</td>\n",
       "      <td>91.260181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.109028</td>\n",
       "      <td>0.499561</td>\n",
       "      <td>4.418122</td>\n",
       "      <td>13.831283</td>\n",
       "      <td>34.608052</td>\n",
       "      <td>30.413081</td>\n",
       "      <td>12.934202</td>\n",
       "      <td>1.290450</td>\n",
       "      <td>0.522391</td>\n",
       "      <td>11.496335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.258100</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>96.050000</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.276700</td>\n",
       "      <td>83.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.620050</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.275000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>209.750000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.997200</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>242.400000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>6.107000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex         bmi          bp          s1          s2  \\\n",
       "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
       "mean    48.518100    1.468326   26.375792   94.647014  189.140271  115.439140   \n",
       "std     13.109028    0.499561    4.418122   13.831283   34.608052   30.413081   \n",
       "min     19.000000    1.000000   18.000000   62.000000   97.000000   41.600000   \n",
       "25%     38.250000    1.000000   23.200000   84.000000  164.250000   96.050000   \n",
       "50%     50.000000    1.000000   25.700000   93.000000  186.000000  113.000000   \n",
       "75%     59.000000    2.000000   29.275000  105.000000  209.750000  134.500000   \n",
       "max     79.000000    2.000000   42.200000  133.000000  301.000000  242.400000   \n",
       "\n",
       "               s3          s4          s5          s6  \n",
       "count  442.000000  442.000000  442.000000  442.000000  \n",
       "mean    49.788462    4.070249    4.641411   91.260181  \n",
       "std     12.934202    1.290450    0.522391   11.496335  \n",
       "min     22.000000    2.000000    3.258100   58.000000  \n",
       "25%     40.250000    3.000000    4.276700   83.250000  \n",
       "50%     48.000000    4.000000    4.620050   91.000000  \n",
       "75%     57.750000    5.000000    4.997200   98.000000  \n",
       "max     99.000000    9.090000    6.107000  124.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types are float64, so we ensured they are numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking missing data and Scaling data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the diabetes dataset, we opted for StandardScaler due to its effectiveness in handling features with varying magnitudes. This choice was motivated by the recognition that the dataset's features, such as blood pressure readings and body mass index (BMI) measurements, might exhibit different scales. StandardScaler was preferred for its robustness and suitability to our dataset's characteristics. While it maintains the shape of the original distribution of features, albeit centered at zero and scaled to unit variance, it also ensures that the scaled features still retain their original relative distances and relationships.\n",
    "\n",
    "StandardScaler standardizes features by removing the mean and scaling to unit variance, making it suitable for datasets where features have varying magnitudes. This approach ensures model stability by being less sensitive to outliers and preserves interpretability by retaining original feature distributions.\n",
    "\n",
    "In contrast, we refrained from using MinMaxScaler. This scaler scales features to a fixed range (for example [0,1]), which may be unsuitable for datasets with unknown feature distributions or varying magnitudes. Additionally, MinMaxScaler is more sensitive to outliers, which could distort the scaling process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data found!\n",
      "\n",
      "Number of instances in training set: 419\n",
      "Number of instances in testing set: 23\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "if missing_values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "else:\n",
    "    print(\"No missing data found!\\n\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, diabetes.target, test_size=0.05)\n",
    "\n",
    "print(\"Number of instances in training set:\", len(X_train))\n",
    "print(\"Number of instances in testing set:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dataset after scaling it to standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.800500  1.065488  1.297088  0.459841 -0.929746 -0.732065 -0.912451   \n",
      "1 -0.039567 -0.938537 -1.082180 -0.553505 -0.177624 -0.402886  1.564414   \n",
      "2  1.793307  1.065488  0.934533 -0.119214 -0.958674 -0.718897 -0.680245   \n",
      "3 -1.872441 -0.938537 -0.243771 -0.770650  0.256292  0.525397 -0.757647   \n",
      "4  0.113172 -0.938537 -0.764944  0.459841  0.082726  0.327890  0.171178   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.054499  0.418531 -0.370989  \n",
      "1 -0.830301 -1.436589 -1.938479  \n",
      "2 -0.054499  0.060156 -0.545154  \n",
      "3  0.721302  0.476983 -0.196823  \n",
      "4 -0.054499 -0.672502 -0.980568  \n"
     ]
    }
   ],
   "source": [
    "sdf = pd.DataFrame(data=scaled_features, columns=diabetes.feature_names)\n",
    "print(sdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Functions’ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the LaTeX formats for the formulas of the mentioned loss functions:\n",
    "\n",
    "1. **Mean Squared Error (MSE)**:\n",
    "$  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $\n",
    "\n",
    "2. **Mean Absolute Error (MAE)**:\n",
    "$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**:\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $\n",
    "\n",
    "4. **R² Score (Coefficient of Determination)**:\n",
    "$ R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "\n",
    "Where:\n",
    "-  **n** is the number of observations,\n",
    "- $ y_i $ is the actual value,\n",
    "- $ \\hat{y}_i $ is the predicted value,\n",
    "- $ \\bar{y} $ is the mean of the actual values of the dependent variable.\n",
    "- $ SS_{\\text{res}} $ is the sum of squares of residuals,\n",
    "- $ SS_{\\text{tot}} $ is the total sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred, act):\n",
    "    mse = 0\n",
    "    n = len(pred)\n",
    "    for i in range(n):\n",
    "        value = (pred[i] - act[i]) ** 2\n",
    "        mse += value\n",
    "    mse /= n\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, act):\n",
    "    mae = 0\n",
    "    n = len(pred)\n",
    "    for i in range(n):\n",
    "        value = abs(pred[i] - act[i])\n",
    "        mae += value\n",
    "    mae /= n\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RMSE(pred, act):\n",
    "    mse = MSE(pred, act)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_Score(pred, act):\n",
    "    n = len(pred)\n",
    "    pred_sum = np.sum(pred)\n",
    "    pred_squared_sum = np.sum(np.square(pred))\n",
    "    act_sum = np.sum(act)\n",
    "    act_squared_sum = np.sum(np.square(act))\n",
    "    pred_act_sum = np.sum([pred[i] * act[i] for i in range(len(pred))])\n",
    "    numerator = n * pred_act_sum - pred_sum * act_sum\n",
    "    pred_term = n * pred_squared_sum - pred_sum ** 2\n",
    "    act_term = n * act_squared_sum - act_sum ** 2\n",
    "    denominator = math.sqrt(pred_term) * math.sqrt(act_term)\n",
    "    r2_score = numerator / denominator\n",
    "    return r2_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Building and Training the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_max = max(max(y_test), max(y_pred)) + 20\n",
    "plt_min = 0\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlim(plt_min, plt_max)\n",
    "plt.ylim(plt_min, plt_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|    Data Type/Optimizer       |          MSE          |          MAE          |          RMSE          |          R2 Score          |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|         Train Set               2809.42203706178952      42.98814838878361        53.00398133217720          0.72497262446423      |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|          Test Set               3881.57355806990654      48.55429534239421        62.30227570538581          0.61854144735326      |\n",
      "|------------------------------------------------------------------------------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "mse_train = MSE(y_train, y_train_pred)\n",
    "mae_train = MAE(y_train, y_train_pred)\n",
    "rmse_train = RMSE(y_train, y_train_pred)\n",
    "r2_train = R2_Score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "mae_test = MAE(y_test, y_pred)\n",
    "rmse_test = RMSE(y_test, y_pred)\n",
    "r2_test = R2_Score(y_test, y_pred)\n",
    "\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(\"|    Data Type/Optimizer       |          MSE          |          MAE          |          RMSE          |          R2 Score          |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(f\"|         Train Set               {mse_train:.14f}      {mae_train:.14f}        {rmse_train:.14f}          {r2_train:.14f}      |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n",
    "print(f\"|          Test Set               {mse_test:.14f}      {mae_test:.14f}        {rmse_test:.14f}          {r2_test:.14f}      |\")\n",
    "print(\"|------------------------------------------------------------------------------------------------------------------------------------|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30e47140>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set OLS Statistics:\n",
      "  Feature      Slope   Intercept  R2-value       P-value  Std Error\n",
      "0     age  13.708379  151.793208  0.032228  2.209205e-04   3.678626\n",
      "1     sex   2.223357  151.717333  0.000835  5.552590e-01   3.766008\n",
      "2     bmi  45.271337  151.761203  0.342267  7.687421e-40   3.073247\n",
      "3      bp  33.502681  152.140960  0.190542  6.395687e-21   3.381536\n",
      "4      s1  15.956825  151.974263  0.041712  2.524756e-05   3.745389\n",
      "5      s2  12.875436  151.879188  0.026899  7.516553e-04   3.792309\n",
      "6      s3 -30.639197  151.743279  0.157131  3.228825e-17   3.475027\n",
      "7      s4  32.975838  151.938886  0.183689  3.775480e-20   3.404191\n",
      "8      s5  43.642627  152.435797  0.321410  5.322191e-37   3.105396\n",
      "9      s6  28.926491  152.212599  0.140161  2.178134e-15   3.508504\n",
      "\n",
      "Test Set OLS Statistics:\n",
      "  Feature      Slope   Intercept  R2-value   P-value  Std Error\n",
      "0     age  33.532632  156.549648  0.132145  0.088185  18.752331\n",
      "1     sex  24.043918  161.181483  0.094815  0.152892  16.211565\n",
      "2     bmi  43.404734  158.942258  0.375988  0.001863  12.202154\n",
      "3      bp  44.709963  149.465683  0.282321  0.009080  15.555651\n",
      "4      s1  20.235573  153.819083  0.099300  0.143032  13.299094\n",
      "5      s2  18.335667  155.579033  0.092890  0.157345  12.503561\n",
      "6      s3 -26.625469  159.284347  0.136653  0.082547  14.603966\n",
      "7      s4  35.892148  155.334836  0.209589  0.028044  15.210090\n",
      "8      s5  44.127515  146.482365  0.297705  0.007082  14.789960\n",
      "9      s6  39.042290  147.589272  0.265247  0.011909  14.179838\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "ols_stats_train = []\n",
    "for i in range(len(X_train.T)): \n",
    "    slope, intercept, r_value, p_value, std_err = linregress(X_train.T[i], y_train)\n",
    "    ols_stats_train.append({\n",
    "        'Feature': sdf.columns[i],\n",
    "        'Slope': slope,\n",
    "        'Intercept': intercept,\n",
    "        'R2-value': r_value ** 2,\n",
    "        'P-value': p_value,\n",
    "        'Std Error': std_err\n",
    "    })\n",
    "\n",
    "ols_stats_train_df = pd.DataFrame(ols_stats_train)\n",
    "ols_stats_test = []\n",
    "for i in range(len(X_test.T)): \n",
    "    slope, intercept, r_value, p_value, std_err = linregress(X_test.T[i], y_test)\n",
    "    ols_stats_test.append({\n",
    "        'Feature': sdf.columns[i],\n",
    "        'Slope': slope,\n",
    "        'Intercept': intercept,\n",
    "        'R2-value': r_value ** 2,\n",
    "        'P-value': p_value,\n",
    "        'Std Error': std_err\n",
    "    })\n",
    "\n",
    "ols_stats_test_df = pd.DataFrame(ols_stats_test)\n",
    "\n",
    "print(\"Training Set OLS Statistics:\")\n",
    "print(ols_stats_train_df)\n",
    "\n",
    "print(\"\\nTest Set OLS Statistics:\")\n",
    "print(ols_stats_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.526\n",
      "Model:                            OLS   Adj. R-squared:                  0.514\n",
      "Method:                 Least Squares   F-statistic:                     45.20\n",
      "Date:                Mon, 22 Apr 2024   Prob (F-statistic):           5.08e-60\n",
      "Time:                        16:32:12   Log-Likelihood:                -2258.1\n",
      "No. Observations:                 419   AIC:                             4538.\n",
      "Df Residuals:                     408   BIC:                             4583.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        152.3381      2.625     58.031      0.000     147.178     157.499\n",
      "x1            -0.3712      2.860     -0.130      0.897      -5.993       5.250\n",
      "x2           -12.1831      2.967     -4.107      0.000     -18.015      -6.351\n",
      "x3            25.3141      3.226      7.848      0.000      18.973      31.655\n",
      "x4            14.5109      3.175      4.570      0.000       8.269      20.752\n",
      "x5           -38.6620     20.058     -1.928      0.055     -78.091       0.767\n",
      "x6            21.1209     16.278      1.297      0.195     -10.879      53.121\n",
      "x7             5.0737     10.360      0.490      0.625     -15.292      25.439\n",
      "x8             9.1358      7.864      1.162      0.246      -6.324      24.596\n",
      "x9            36.5872      8.241      4.439      0.000      20.387      52.788\n",
      "x10            4.0741      3.186      1.279      0.202      -2.189      10.337\n",
      "==============================================================================\n",
      "Omnibus:                        1.338   Durbin-Watson:                   1.969\n",
      "Prob(Omnibus):                  0.512   Jarque-Bera (JB):                1.275\n",
      "Skew:                           0.001   Prob(JB):                        0.529\n",
      "Kurtosis:                       2.730   Cond. No.                         21.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "X = add_constant(X_train)\n",
    "model = OLS(y_train, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.528\n",
      "Model:                            OLS   Adj. R-squared:                  0.135\n",
      "Method:                 Least Squares   F-statistic:                     1.343\n",
      "Date:                Mon, 22 Apr 2024   Prob (F-statistic):              0.310\n",
      "Time:                        16:32:12   Log-Likelihood:                -124.08\n",
      "No. Observations:                  23   AIC:                             270.2\n",
      "Df Residuals:                      12   BIC:                             282.6\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.6989     19.560      7.653      0.000     107.082     192.316\n",
      "x1             4.1489     33.441      0.124      0.903     -68.713      77.011\n",
      "x2            11.8434     24.121      0.491      0.632     -40.712      64.399\n",
      "x3            21.0970     24.759      0.852      0.411     -32.848      75.042\n",
      "x4            17.7891     26.730      0.666      0.518     -40.451      76.029\n",
      "x5           -24.8100    194.055     -0.128      0.900    -447.621     398.001\n",
      "x6            40.8042    172.953      0.236      0.817    -336.029     417.637\n",
      "x7           -19.3182     67.608     -0.286      0.780    -166.624     127.988\n",
      "x8           -33.4648     69.119     -0.484      0.637    -184.062     117.132\n",
      "x9            36.7871     86.597      0.425      0.678    -151.892     225.467\n",
      "x10           -9.8573     31.543     -0.313      0.760     -78.584      58.870\n",
      "==============================================================================\n",
      "Omnibus:                        0.331   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.847   Jarque-Bera (JB):                0.495\n",
      "Skew:                          -0.119   Prob(JB):                        0.781\n",
      "Kurtosis:                       2.322   Cond. No.                         40.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = add_constant(X_test)\n",
    "model = OLS(y_test, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "x1 = age\n",
    "\n",
    "x2 = sex\n",
    "\n",
    "x3 = bmi (body mass index)\n",
    "\n",
    "x4 = bp (blood pressure)\n",
    "\n",
    "x5 = s1\n",
    "\n",
    "x6 = s2\n",
    "\n",
    "x7 = s3\n",
    "\n",
    "x8 = s4\n",
    "\n",
    "x9 = s5\n",
    "\n",
    "x10 = s6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    " * The MSE for the training set (2837.47) is lower than the MSE for the test set (3330.65), which is expected because the model is typically optimized for the training data.\n",
    " * The MAE for the training set (43.05) is lower than the MAE for the test set (47.86), which is consistent with the MSE trend.\n",
    " * The RMSE for the training set (53.27) is lower than the RMSE for the test set (57.71), which aligns with the MSE and MAE results.\n",
    " * The R² score for the training set (0.71) is lower than the R² score for the test set (0.81), which is unexpected, as the model is typically expected to perform better on the training data. The higher R² score for the test set compared to the training set may indicate potential issues, such as overfitting or data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. \n",
    "\n",
    "**R² (R-squared)**:\n",
    "- The R² value, also known as the coefficient of determination, represents the proportion of the variance in the dependent variable (target) that can be explained by the independent variables (features) in the regression model.\n",
    "- It ranges from 0 to 1, where a value of 1 indicates a perfect fit, meaning the model explains 100% of the variance in the target variable.\n",
    "- A high R² value (closer to 1) suggests that the model fits the data well and can accurately predict the target variable based on the independent variables.\n",
    "- A low R² value (closer to 0) indicates that the model does not adequately capture the relationship between the independent variables and the target variable, and has a poor fit.\n",
    "\n",
    "**Adjusted R²**:\n",
    "- The Adjusted R² is a modified version of the R² that takes into account the number of independent variables and the sample size.\n",
    "- It adjusts the R² value downward to account for the potential overfitting that can occur when adding more independent variables to the model.\n",
    "- The Adjusted R² is always lower than or equal to the R² value, and it provides a more conservative estimate of the model's explanatory power.\n",
    "- A higher Adjusted R² value (closer to the R² value) suggests that the addition of independent variables is justified and improves the model's predictive power.\n",
    "- A lower Adjusted R² value (much lower than the R² value) may indicate that the additional independent variables are not contributing significantly to the model's performance, and the model may be overfitted.\n",
    "\n",
    "**Implications of High or Low Values**:\n",
    "- High R² and Adjusted R² values (close to 1) generally indicate a good fit and a strong relationship between the independent variables and the target variable. However, it's important to note that a high R² alone does not necessarily imply a useful or reliable model, as other factors like multicollinearity, outliers, and model assumptions should also be considered.\n",
    "- Low R² and Adjusted R² values (closer to 0) suggest that the model has a poor fit and may not be capturing the underlying relationship between the independent variables and the target variable effectively. This could be due to missing important features, incorrect model assumptions, or the presence of non-linear relationships that cannot be adequately captured by a linear regression model.\n",
    "\n",
    "**Differences between R² and Adjusted R²**:\n",
    "- The main difference between R² and Adjusted R² is that the Adjusted R² accounts for the number of independent variables and the sample size, while the R² does not.\n",
    "- The Adjusted R² is always lower than or equal to the R² value, and the difference between them becomes more significant as the number of independent variables increases relative to the sample size.\n",
    "- The Adjusted R² is useful for comparing models with different numbers of independent variables, as it penalizes models with an excessive number of predictors that do not significantly improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \n",
    "Explanation of p-values:\n",
    "\n",
    "The p-value is the probability of obtaining a test statistic at least as extreme as the one observed, assuming that the null hypothesis (the coefficient is zero) is true.\n",
    "In other words, the p-value represents the likelihood of observing the given result by chance if the independent variable has no effect on the dependent variable.\n",
    "A smaller p-value indicates stronger evidence against the null hypothesis, suggesting that the independent variable is statistically significant in predicting the dependent variable.\n",
    "\n",
    "Appropriate value for p-values:\n",
    "\n",
    "The conventional threshold for statistical significance is typically set at 0.05 (5%).\n",
    "If the p-value for an independent variable is less than 0.05, it is considered statistically significant, and we can reject the null hypothesis, indicating that the variable is likely to have a non-zero effect on the dependent variable.\n",
    "If the p-value is greater than 0.05, it is generally considered statistically insignificant, and we fail to reject the null hypothesis, suggesting that the variable may not have a significant effect on the dependent variable.\n",
    "\n",
    "Columns with suitable p-values:\n",
    "\n",
    "Based on the OLS regression results, the following columns (independent variables) have p-values less than 0.05, indicating statistical significance:\n",
    "\n",
    "x2: p-value = 0.000\n",
    "\n",
    "x3: p-value = 0.000\n",
    "\n",
    "x4: p-value = 0.000\n",
    "\n",
    "x5: p-value = 0.041\n",
    "\n",
    "x9: p-value = 0.000\n",
    "\n",
    "These columns are considered statistically significant predictors of the dependent variable (y) at the 5% significance level.\n",
    "The remaining columns (x1, x6, x7, x8, and x10) have p-values greater than 0.05, suggesting that they may not be statistically significant predictors of the dependent variable in this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. \n",
    "p-values:\n",
    "\n",
    "Features with p-values less than the conventional threshold of 0.05 are considered statistically significant.\n",
    "Based on the p-values, the most significant features in predicting the diabetic condition are:\n",
    "x2: p-value = 0.000\n",
    "x3: p-value = 0.000\n",
    "x4: p-value = 0.000\n",
    "x5: p-value = 0.041\n",
    "x9: p-value = 0.000\n",
    "\n",
    "Regression Coefficients:\n",
    "\n",
    "The regression coefficients represent the change in the dependent variable (diabetic condition) associated with a one-unit increase in the corresponding feature, holding all other features constant.\n",
    "Features with larger regression coefficients (in absolute value) have a greater impact on the dependent variable.\n",
    "Positive coefficients indicate a positive relationship (an increase in the feature leads to an increase in the diabetic condition), while negative coefficients indicate a negative relationship (an increase in the feature leads to a decrease in the diabetic condition).\n",
    "Based on the regression coefficients, the features with the largest impact (in absolute value) are:\n",
    "x3: Coefficient = 23.8486 (positive relationship)\n",
    "x4: Coefficient = 15.8448 (positive relationship)\n",
    "x5: Coefficient = -41.5275 (negative relationship)\n",
    "x9: Coefficient = 36.4579 (positive relationship)\n",
    "\n",
    "Feature Importance Assessment:\n",
    "\n",
    "Combining the information from p-values and regression coefficients, the most important features in predicting an individual's diabetic condition appear to be:\n",
    "\n",
    "x3: Statistically significant (p-value = 0.000) and positive relationship with a large coefficient (23.8486)\n",
    "x4: Statistically significant (p-value = 0.000) and positive relationship with a moderate coefficient (15.8448)\n",
    "x5: Statistically significant (p-value = 0.041) and negative relationship with a large coefficient (-41.5275)\n",
    "x9: Statistically significant (p-value = 0.000) and positive relationship with a large coefficient (36.4579)\n",
    "Features x2 and x6 also have relatively low p-values (0.000 and 0.109, respectively), indicating potential significance, but their coefficients are smaller in magnitude compared to the features mentioned above.\n",
    "\n",
    "Features x1, x7, x8, and x10 have relatively high p-values (> 0.05), suggesting they may not be statistically significant predictors of the diabetic condition in this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
